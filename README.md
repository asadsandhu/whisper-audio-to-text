# whisper-audio-to-text
A simple implementation of OpenAIâ€™s Whisper for transcribing MP3 files on Google Colab.

Here's the **final enhanced README.md** with the **updated usage instructions** explaining both **uploading a custom file** and **using the sample file** from GitHub.  

---

# **Whisper Audio-to-Text (Google Colab)**  

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/)  
[![Google Colab](https://img.shields.io/badge/Google%20Colab-Compatible-orange?logo=googlecolab)](https://colab.research.google.com/)  
[![OpenAI Whisper](https://img.shields.io/badge/OpenAI-Whisper-brightgreen?logo=openai)](https://github.com/openai/whisper)  
[![License](https://img.shields.io/github/license/asadsandhu/whisper-audio-to-text)](LICENSE)  

---

## ğŸš€ **Overview**  
This repository provides a **Google Colab-based implementation** of OpenAIâ€™s **Whisper AI** for transcribing audio files into text.  
Simply **clone the repo, run the notebook, upload an audio file, and get an accurate transcription in seconds!**  

âœ… **No setup required** â€“ Just open the `.ipynb` file in Colab  
âœ… **User-friendly** â€“ Upload an audio file, run a single command, and get transcriptions  
âœ… **Supports multiple languages** with the **Whisper `medium` model**  
âœ… **Works with multiple audio formats** including MP3, WAV, M4A, and FLAC  

---

## ğŸ“Œ **Supported Audio Formats**  
Whisper AI supports a variety of common audio formats. You can upload files in any of the following formats:  

| **Format** | **File Extension** | **Description** |
|------------|--------------------|----------------|
| **MP3** | `.mp3` | Compressed audio format, widely used |
| **WAV** | `.wav` | High-quality, uncompressed audio |
| **M4A** | `.m4a` | Common format for iOS recordings |
| **FLAC** | `.flac` | Lossless audio format, high fidelity |

ğŸ’¡ **Note:** Files in other formats can be converted using FFmpeg before transcription.

---

## ğŸ“– **How to Use**  

### **1ï¸âƒ£ Clone This Repository in Google Colab**  
Open a new Colab notebook and run the following:  

```bash
!git clone https://github.com/asadsandhu/whisper-audio-to-text.git
%cd whisper-audio-to-text
```

### **2ï¸âƒ£ Install Required Dependencies**  
Run the following commands one by one to set up **Whisper AI** and **FFmpeg**:  

```bash
# Install Whisper AI
!pip install git+https://github.com/openai/whisper.git
```

```bash
# Install FFmpeg (required for audio processing)
!sudo apt update && sudo apt install ffmpeg
```

---

### **3ï¸âƒ£ Upload an Audio File (Optional - Skip if using Sample.mp3)**  
If you **want to transcribe your own audio file**, run this in a Colab cell:  

```python
from google.colab import files
uploaded = files.upload()
```

ğŸ”¹ **After uploading your file, remember its name.**  
ğŸ”¹ **In step 5, replace `"Sample.mp3"` with the name of your uploaded file.**  

---

### **4ï¸âƒ£ (Alternative) Use the Sample Audio File (Skip if you uploaded your own)**  
If you **donâ€™t want to upload a file** and just want to test Whisper AI, run this command:  

```bash
!wget https://github.com/asadsandhu/whisper-audio-to-text/raw/main/Sample.mp3 -O Sample.mp3
```

ğŸ”¹ This will **automatically download** a sample MP3 file (`Sample.mp3`) from GitHub.  
ğŸ”¹ **If you already uploaded a file, skip this step.**  

---

### **5ï¸âƒ£ Run Whisper AI for Transcription**  
Now, transcribe the audio file with Whisper:  

```bash
!whisper "Sample.mp3" --model medium
```

ğŸ”¹ **If you uploaded your own file in step 3**, replace `"Sample.mp3"` with **your file name**.  
ğŸ”¹ **You can change the model** by replacing `medium` with any of the available Whisper models.  

#### **Available Whisper Models & Their Performance**  

| **Model** | **Size** | **Speed** | **Accuracy** | **Best For** |
|-----------|---------|----------|--------------|--------------|
| `tiny`    | 39 MB   | ğŸš€ Very Fast  | âŒ Low Accuracy  | Quick testing, low-end devices |
| `base`    | 74 MB   | âš¡ Fast  | ğŸ”¸ Moderate Accuracy | Short recordings, general use |
| `small`   | 244 MB  | âš¡ Moderate  | ğŸ”¹ Good Accuracy  | Standard transcription tasks |
| `medium`  | 769 MB  | â³ Slower  | âœ… High Accuracy | Most users, multilingual support |
| `large`   | 1550 MB | ğŸ•’ Slowest  | ğŸ”¥ Best Accuracy | Research, high-quality needs |

ğŸ”¹ **Larger models provide better accuracy but take longer to process**.  
ğŸ”¹ **If speed is a priority**, use `small` or `base`. If accuracy is **more important**, use `medium` or `large`.  
ğŸ”¹ **Example: Using the large model**  

```bash
!whisper "Sample.mp3" --model large
```

---

## ğŸ’¡ **Example Usage Flow**  

| **Scenario** | **Steps to Follow** |
|-------------|----------------------|
| **Upload your own audio file** | Run **Step 3** â†’ Skip **Step 4** â†’ Run **Step 5** (rename file) |
| **Use the sample audio file** | Skip **Step 3** â†’ Run **Step 4** â†’ Run **Step 5** |

---

## ğŸ”Š **Sample File for Testing**  
A sample MP3 file (`Sample.mp3`) is included in this repository for quick testing. You can use it to check the functionality before uploading your own files.  

---

## ğŸ“Œ **Requirements**  
- **Google Colab** (Runs in the cloud, no local installation needed)  
- **Python 3.7+**  
- **Whisper AI** (`pip install whisper`)  
- **FFmpeg** (pre-installed in Colab)  

---

## ğŸ¯ **Why Use This Repository?**  
âœ” **Minimal Effort** â€“ Just upload and run, no extra configurations  
âœ” **Highly Accurate** â€“ Uses Whisperâ€™s `medium` model for precise transcriptions  
âœ” **Cloud-Based** â€“ Runs on **Google Colabâ€™s free GPU resources**  
âœ” **Multiple Formats** â€“ Supports MP3, WAV, M4A, FLAC  

---

## ğŸ¤ **Contributing**  
Contributions are welcome! If you find any issues or have ideas for improvements, feel free to submit a **pull request** or open an **issue**.  

---

## ğŸ“œ **License**  
This project is licensed under the **MIT License**.  

---

### ğŸ”— **Connect with Me**  
If you find this repository helpful, feel free to **star ğŸŒŸ it on GitHub**! ğŸš€  

---
